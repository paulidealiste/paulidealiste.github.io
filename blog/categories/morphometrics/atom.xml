<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Morphometrics | Creative morphometrics]]></title>
  <link href="http://paulidealiste.github.io/blog/categories/morphometrics/atom.xml" rel="self"/>
  <link href="http://paulidealiste.github.io/"/>
  <updated>2014-09-02T14:35:02+02:00</updated>
  <id>http://paulidealiste.github.io/</id>
  <author>
    <name><![CDATA[Miloš Blagojević]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Automated Outlines With openCV in Python]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/08/05/automated-outlines-with-opencv-in-python/"/>
    <updated>2014-08-05T20:06:18+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/08/05/automated-outlines-with-opencv-in-python</id>
    <content type="html"><![CDATA[<p>Quantification of biological shape often relies on manual extraction of information from a set of digital images or 3D models, like manual landmark placement or outlining the object of interest by hand. With computer vision approach and, especially, with the help of the <a href = "http://opencv.org">openCV</a> library, a set of image manipulation tecniques as well as automated feature extractions are facilitated to a large extent. Since there are excellent python bindings for this library it is easy to test ideas for image analysis and object extraction in the context of geometric morphometrics.</p>

<p>This post will serve as a general introduction to openCV in python, and will continue on the earlier posts about the outline extraction from digital photos usual in GM research. The sample image can be obtained <a href = "http://goo.gl/eDtqdn"> here</a>.</p>

<p>```python Library import, reading and displaying the image</p>

<p>import numpy as np
import cv2 #this is the main openCV class, the python binding file should be in /pythonXX/Lib/site-packages
from matplotlib import pyplot as plt</p>

<p>gwash = cv2.imread(&ldquo;~/taster1.JPG&rdquo;) #import image
gwashBW = cv2.cvtColor(gwash, cv2.COLOR_BGR2GRAY) #change to grayscale</p>

<p>plt.imshow(gwashBW, &lsquo;gray&rsquo;) #this is matplotlib solution (Figure 1)
plt.xticks([]), plt.yticks([])
plt.show()</p>

<p>cv2.imshow(&lsquo;gwash&rsquo;, gwashBW) #this is for native openCV display
cv2.waitKey(0)
```
<img class="center" src="/images/figure_1gbw.png" width="600" height="468" title="&lsquo;Original image&rsquo;" ></p>

<p>This image is suitable for automated online extraction of the skull, since there is a significant ammount of contrast of the object and the background. The idea is to use thresholding and a bit of erosion around the edges to delimit the skull from the rest of the picture and then apply automated contour extractions.</p>

<p>```python Image threshold, erosion and contour extraction</p>

<p>ret,thresh1 = cv2.threshold(gwashBW,15,255,cv2.THRESH_BINARY) #the value of 15 is chosen by trial-and-error to produce the best outline of the skull
kernel = np.ones((5,5),np.uint8) #square image kernel used for erosion
erosion = cv2.erode(thresh1, kernel,iterations = 1) #refines all edges in the binary image</p>

<p>opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel) #this is for further removing small noises and holes in the image</p>

<p>plt.imshow(closing, &lsquo;gray&rsquo;) #Figure 2
plt.xticks([]), plt.yticks([])
plt.show()</p>

<p>contours, hierarchy = cv2.findContours(closing,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) #find contours with simple approximation</p>

<p>cv2.imshow(&lsquo;cleaner&rsquo;, closing) #Figure 3
cv2.drawContours(closing, contours, -1, (255, 255, 255), 4)
cv2.waitKey(0)
```
<img class="center" src="/images/figure_2teoc.png" width="600" height="470" title="&lsquo;Binary image&rsquo;" >
<img class="center" src="/images/figure_3econ.png" width="600" height="468" title="&lsquo;Extracted contours&rsquo;" ></p>

<p>Finally, since other objects of no interest are also outlined in Figure 3, the skull outline must be identified in the array list contours. This can be done by a for loop, and the openCV method for calculating outline areas, as the skull outline is the longest continual outline in the image.</p>

<p>```python Calculating outline areas and extracting the skull outline</p>

<p>areas = [] #list to hold all areas</p>

<p>for contour in contours:</p>

<pre><code>ar = cv2.contourArea(contour)
areas.append(ar)
</code></pre>

<p>max_area = max(areas)
max_area_index = areas.index(max_area) #index of the list element with largest area</p>

<p>cnt = contours[max_area_index] #largest area contour</p>

<p>cv2.drawContours(closing, [cnt], 0, (255, 255, 255), 3, maxLevel = 0)
cv2.imshow(&lsquo;cleaner&rsquo;, closing)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
<img class="center" src="/images/figure_4fec.png" width="600" height="469" title="&lsquo;One contour&rsquo;" ></p>

<p>The extracted contour is a numpy array with xy coordinates of contour points in rows, so it can be directly used for sampling landmarks along the outline for fitting the normalized Fourier transform and doing shape analysis further. Of course, the procedure can be easily generalized to work over all images in a dataset, extract the contours with largest areas from each image, and generate a dataset for shape analysis.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Project and Explore]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/07/07/python-project-and-explore/"/>
    <updated>2014-07-07T17:21:08+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/07/07/python-project-and-explore</id>
    <content type="html"><![CDATA[<p>Since Procrustes superimposition introduces the data into a curved shape space which corresponds to a hyperhemisphere of radius 1 with numerous dimensions (as defined by Rohlf, 1999<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>), usual multivariate statistical methods are not readily applicable to such data. This data must be projected to a flat, Euclidean tangent space, that is in contact with the hyperhemisphere in one point, taken as a mean shape of the whole dataset. This projection can be applied only if the variation in shapes in not overtly large so that their &ldquo;shadows&rdquo; on a flat space are not too far apart. In this post, data will be generated as usual and Procrustes procedures will be taken from previous posts, using defined functions <em>centsiz</em>, <em>transScale</em>, <em>mshapr</em>, <em>pProc</em> and <em>pGP</em>.</p>

<p>```python Importing libraries, generating data and utility functions
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import Pycluster as pyc
import brewer2mpl
from mpl_toolkits.mplot3d import Axes3D
from sklearn.decomposition import PCA</p>

<p>coordstest = np.vstack([np.random.uniform(175, 210, 10),    #slightly larger variation</p>

<pre><code>                    np.random.uniform(175, 210, 10)]).T 
</code></pre>

<p>coords = np.vstack([np.random.multivariate_normal(coordstest[i,:], [[10,0],[0,1]], 200) for i in range(10)])
coordinates = pd.Series((np.arange(0,10).reshape(-1,1)*np.ones(200).reshape(1,-1)).flatten()) #coordinates column
individuals = np.tile(np.arange(0,200),10) #individuals column
allCoords = pd.DataFrame(coords, columns = [&lsquo;x&rsquo;,&lsquo;y&rsquo;])
allCoords[&lsquo;coordinates&rsquo;] = coordinates
allCoords[&lsquo;individuals&rsquo;] = individuals
allCoords = allCoords.sort_index(by = [&lsquo;individuals&rsquo;,&lsquo;coordinates&rsquo;])
```
After Procrustes superimposition, data can be projected orthogonally and stereographically. More common method is the orthogonal projection which minimizes lagre shape differences between landmark configurations. The procedure is based on Rohlf, 1999, suggesting that the matrix of aligned centered preshapes should be multiplied by the mean shape of unit centroid size, subtracted from the identity matrix of comparable dimensionality (Claude, 2008).</p>

<p>```python Orthogonal projection of superimposed data, Procrustes superimposition and projection
def ortproj(A, numland, dim, numind): #where A is a pandas dataframe (tempCoords), numind =  landmarks, numind =  individuals
  mshape = A.iloc[:,0:2].groupby(A.iloc[:,2]).mean()
  mshStd = mshape/centsize(mshape)
  mshMel = pd.melt(mshStd).drop(&lsquo;variable&rsquo;,1).T
  #mshRep = pd.concat([mshMel]<em>numind, ignore_index = True) #calculate repeating size standardized meanShape
  mshRep = np.dot(np.ones([numind,1]), mshMel)
  simDia = np.identity(numland * dim) #identity matrix
  #lonWid = A[[&ldquo;x&rdquo;,&ldquo;y&rdquo;]].values.reshape(numind,numland</em>dim) #must have column names &ldquo;x&rdquo; and &ldquo;y&rdquo; for coordinates
  lonWidX = A[&ldquo;x&rdquo;].values.reshape(numind,numland)
  lonWidY = A[&ldquo;y&rdquo;].values.reshape(numind,numland)
  lonWid = np.concatenate((lonWidX, lonWidY), axis = 1)
  temp1 = simDia &ndash; np.dot(mshMel.T, mshMel)
  Xi = np.dot(lonWid, temp1) #orthogonal according to Rholf
  Xproj = Xi + mshRep
  return Xproj</p>

<p>procCoords = pGP(allCoords, 200,2,10) #perform Procrustes superimposition
procoordinates = np.tile(np.arange(0,10),200)
procindividuals = allCoords[&lsquo;individuals&rsquo;]
procCoords[&lsquo;coordinates&rsquo;] = procoordinates
procCoords[&lsquo;individuals&rsquo;] = sort(procindividuals)
projCoords = ortproj(procCoords, 10, 2, 200) #perform orthogonal projection
```
Numpy array projCoords holds wide representation of projected data (rows are individuals, while columns are all landmarks, first all x and then y coordinates), ready to be used in PCA or any other multivariate method. In order to illustrate potential grouping in PCA morphospace, since the data is randomly generated, a kmeans clustering will be performed with 3 groups, just to effectively split the data. PCA can be done in python in numerous ways, but in this post a PCA decomposition from <em>scikit-learn</em> package is used.</p>

<p>```python PCA, cluster analysis and plots
pca = PCA(n_components = 3)
pca.fit(projCoords)
print(pca.explained_variance_ratio_)</p>

<p>projCoordsP = pca.transform(projCoords) #get the individual scores on PC axes</p>

<p>clusters = pd.Series(pyc.kcluster(projCoordsP, nclusters = 3, method = &lsquo;a&rsquo;, dist = &lsquo;e&rsquo;)[0])
set2 = brewer2mpl.get_map(&lsquo;RdYlBu&rsquo;, &lsquo;diverging&rsquo;, 3).mpl_colors #generate nice colors
projCoordsPa = np.column_stack((projCoordsP, clusters)) #concatenate all for sequential plot-building</p>

<p>group1PCA = projCoordsPa[projCoordsPa[:,3] == 0] #split by group for sequential plot-building
group2PCA = projCoordsPa[projCoordsPa[:,3] == 1]
group3PCA = projCoordsPa[projCoordsPa[:,3] == 2]
fig = plt.figure()
ax = fig.add_subplot(111, projection=&lsquo;3d&rsquo;)
ax.plot(group1PCA[:,0], group1PCA[:,1], group1PCA[:,2], &lsquo;o&rsquo;, c = set2[0], alpha = 1, label = &lsquo;Group1&rsquo;)
ax.plot(group2PCA[:,0], group2PCA[:,1], group2PCA[:,2], &lsquo;o&rsquo;, c = set2[1], alpha = 1, label = &lsquo;Group2&rsquo;)
ax.plot(group3PCA[:,0], group3PCA[:,1], group3PCA[:,2], &lsquo;o&rsquo;, c = set2[2], alpha = 1, label = &lsquo;Group3&rsquo;)
ax.set_title(&ldquo;PCA with grouping according to kmeans 3 group solution&rdquo;)
plt.legend(loc=&lsquo;upper left&rsquo;)
ax.set_xlabel(&lsquo;PC1 (14.45%)&rsquo;)
ax.set_ylabel(&lsquo;PC2 (13.29%)&rsquo;)
ax.set_zlabel(&lsquo;PC3 (12.46%)&rsquo;)
plt.show()
```
Since the data is randomly generated, there is not much structured variation in it, as three of the first PC axes describe 14.45%, 13.29% and 12.46% of total sample variability, respectively. On the other hand, kmeans forces the data into three groups, which is useful for demonstration of plotting in matplotlib with 3D axes, and a groupping structure in PCA scatterplots (Figure 1), similar to real-world data.</p>

<p><img class="center" src="/images/TDPCAscatter.png" width="650" height="484" title="&lsquo;PCA of projected and superimposed data&rsquo;" ></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Rohlf, J.F. 1999. Shape statistics: Procrustes superimpositions and tangent spaces. <em>Journal of Classification</em> <strong>16</strong>: 197-223.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Angles and Nice Plots]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/06/09/simple-angles-and-nice-plots/"/>
    <updated>2014-06-09T17:28:06+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/06/09/simple-angles-and-nice-plots</id>
    <content type="html"><![CDATA[<p>Angles were important for some of the most interesting research in morphometrics. The approach of Rao and Suryawanshi, 1998<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. introduced the angles within the landmark triangulation grids as an alternative to Procrustes superimposition for extracting shape data. This post does not perform the procedures described by Rao (which are ported to R in &ldquo;Geometric morphometrics in R&rdquo; by J.Claude, 2008), but instead aims at extracting angle data, from configurations of landmarks, after Procrustes superimposition. The code presented here is motivated by the <em>polarRotator</em> function from some of the previous pyhton-related posts, and it presents landmark data as polar angles. These angles represent the angular deviation of each landmark from the centroid of the respective configuration (Figure 1), so that the variability in their position with respect to xy centroid coordinates, may represent their shape differences. Since superimposition procedure sets all configurations centroids to the origin, they are all 0,0. Dataset used is the same as for the triangulation post.</p>

<p>```r Plotting the circle, centroid axes and mean configuration
library(geomorph)
library(ggplot2)
library(reshape2)
library(plyr)
theme_set(theme_bw())</p>

<p>load(&ldquo;capSample.RData&rdquo;)</p>

<p>capGPA &lt;&ndash; gpagen(capSample)
capCoords &lt;&ndash; capGPA$coords
mshapeCap &lt;&ndash; mshape(capCoords) #mean configuration is great for illustrations
capCentro &lt;&ndash; capGPA$Csize</p>

<p>circleFun &lt;&ndash; function(center = c(0,0), npoints = 100) #drawing an enlosing circle set at the origin (0,0)
{
  r = 0.5
  tt &lt;&ndash; seq(0,2*pi,length.out = npoints)
  xx &lt;&ndash; center[1] + r * cos(tt)
  yy &lt;&ndash; center[2] + r * sin(tt)
  return(data.frame(x = xx, y = yy))
}</p>

<p>enclosing &lt;&ndash; circleFun(npoints = 100) #it should be centered at zero and have diameter 0.5
ggCirc &lt;&ndash; ggplot(enclosing, aes(x=x,y=y)) + geom_path(size = 1, color = &ldquo;darkgrey&rdquo;, linetype = 1)
ggCirc &lt;&ndash; ggCirc + geom_hline(size = 1, color = &ldquo;darkgrey&rdquo;, linetype = 1) + geom_vline(size = 1, color = &ldquo;darkgrey&rdquo;, linetype = 1)</p>

<p>linesAng &lt;&ndash; data.frame(x1 = c(0, 0, 0, 0), y1 = c(0, 0, 0, 0), x2 = mshapeCap[,1], y2 = mshapeCap[,2]) #point coordinates
linesAng &lt;&ndash; data.frame(linesAng, x3 = linesAng$x2 * 20, y3 = linesAng$y2 *20) #so that the lines would extend through landmarks</p>

<p>ggCirc &lt;&ndash; ggCirc + geom_segment(data = linesAng, aes(x = x1, y = y1, xend = x3, yend = y3), colour = &ldquo;lightblue&rdquo;, size = 1)
ggCirc &lt;&ndash; ggCirc + geom_point(size = 4.2, color = &ldquo;orange&rdquo;, data = data.frame(mshapeCap), aes(x=X1, y = X2))
ggCirc &lt;&ndash; ggCirc + geom_text(data = data.frame(mshapeCap), aes(x=X1, y = X2, label = c(1:16)), vjust = -1.2)
ggCirc &lt;&ndash; ggCirc + coord_cartesian(xlim= c(-0.55, 0.55), ylim= c(-0.55, 0.55))
``` <br/>
<img class="center" src="/images/AnglesLandmarks.png" width="500" height="478" title="&lsquo;Landmarks polar angles&rsquo;" ></p>

<p><em>ggplot2</em> has one great geom, polar_angle() that will transform any shape, from Cartesian to polar coordinates. Unfortunately it does not give polar angles as well, but the plot is informative (Figure 2), since landmarks are ordered according to their angular deviation from 0, i.e. the X and Y axes defining the 0.5 centroid-centered ellipse.</p>

<p><code>r Polar coordinate system in ggplot2
ggPolar &lt;- ggplot(data.frame(mshapeCap), aes(x=X1, y=X2)) + geom_point(size = 4.2, color = "orange")
ggPolar &lt;- ggPolar + geom_text(aes(label = c(1:16)), vjust = 1.5)
ggPolar &lt;- ggPolar + coord_polar(start = 0) + xlab("x") + ylab("y")
</code></p>

<p><img class="center" src="/images/AnglesPolar.png" width="500" height="436" title="&lsquo;Landmarks polar coordinate system&rsquo;" ></p>

<p>Polar angles can be calculated by using the atan2 (arctangent) function, which takes two parameters, x and y and gives one point estimate of the polar angle in radians. This number is really the angle between the positive x-axis of a plane (X from Figure 1) and the point given by its xy coordinates. Since after superimposition the x-axis lies at zero for all landmark configurations, it would be sufficent to use only xy coodinates of landmarks, since centroids are also at 0.</p>

<p>```r Polar angles with atan2 function
polarAngler &lt;&ndash; function(A) #function to calculate polar angles from the array
{
  siz &lt;&ndash; dim(A)[3]
  len &lt;&ndash; dim(A)[1]
  polarAngles &lt;&ndash; vector(&ldquo;list&rdquo;, siz)
  for (i in 1:siz)
  {</p>

<pre><code>temp &lt;- atan2(A[,2,i], A[,1,i])
polarAngles[[i]] &lt;- temp
</code></pre>

<p>  }
  polarAngles &lt;&ndash; array(unlist(polarAngles), dim = c(len,1,siz))
  return(polarAngles)
}</p>

<p>library(circular)
library(colortools)</p>

<p>pAngles &lt;&ndash; polarAngler(capCoords) #angles for all configurations
mAngles &lt;&ndash; apply(pAngles, 1, mean) #mean angles for each landmark
col1 &lt;&ndash; pals(&ldquo;fish&rdquo;) #paletes from colortools
col2 &lt;&ndash; pals(&ldquo;ocean&rdquo;)
col3 &lt;&ndash; pals(&ldquo;mystery&rdquo;)
colorPoint &lt;&ndash; c(col1, col2, col3, &ldquo;#9A76F5&rdquo;) #16 colors for landmarks in whell</p>

<p>plot.circular(circular(t(mAngles), type = &ldquo;angles&rdquo;), sep = 0.0003, col = colorPoint, cex = 1.5)
legend(0.3,0.6, legend = 1:16, fill = colorPoint, cex = 0.7)</p>

<p>```</p>

<p><img class="center" src="/images/AnglesMean.png" width="500" height="436" title="&lsquo;Landmarks ordered by angles&rsquo;" ></p>

<p>Figure 3 shows the distribution of landmarks from along a circular path (0,     π). It is obvious that landmarks form two distinct groups, one above, and one below the x-axis, with the exception of landmarks 7, 8 and 10 which are the most parallel to the x-axis. The proportion of the overall shape variability left in these angles must be thouroghly checked, but it is not easy, since angle-data can not be analysed by conventional statistics, but by circular or compositional methods. R provides some libraries for this, <em>circular</em> and <em>CircStats</em> which are both derived from the book of Jammalamadaka and Sengupta, &ldquo;Topics in circular Statistics&rdquo; from 2001. If one more individual is added to the circle-plot (Figure 3) it can be can visually inspected how much its coordinates (landmark polar angles) deviate from the sample mean (Figure 4).</p>

<p><code>r Adding individual 10 to circular plot
ce &lt;- circular(rbind(t(mAngles), pAngles[,,10])) #deviation of individual 10 from the mean
plot.circular(ce, sep = 0.0003, col = colorPoint, cex = 1.5)
legend(0.3,0.6, legend = 1:16, fill = colorPoint, cex = 0.7)
</code></p>

<p><img class="center" src="/images/AnglesMean2.png" width="500" height="436" title="&lsquo;Landmarks ordered by angles + 10&rsquo;" ></p>

<p> Some variablity is present around landmarks 10, 6 and 5, while others are nearly or completely overlapping. The variability may not be large, but it will be checked in future posts, as well as possible PCA with the angular data.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Rao C.R. and S. Suryawanshi. 1998. Statistical analysis of shape of objects based on landmark data. <em>PNAS</em> <strong>93</strong>: 12132-12136.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Procrustes in Python]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/05/17/complete-procrustes-in-python/"/>
    <updated>2014-05-17T20:38:16+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/05/17/complete-procrustes-in-python</id>
    <content type="html"><![CDATA[<p>Procrustes superimposition is the first analytic step in geometric morphometrics and this post shows one possible solution to performing it in Python<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, using several functions defined in previous posts. First steps include data generation and definition of functions important for extracting shape variables from randomly generated landmark data. These functions are <em>centsize</em> which calculates centroid size from a numpy array (xy data) and <em>transScale</em> which translates landmark coordinates to the origin of the coordinate system and scales them to unit centroid size. The <em>mshapr</em> function is needed in the main superimposition function since it calculates succesive mean shapes (all configurations), excluding the configuration that is currently being rotated.</p>

<p>``` r Import libraries, function definition and data generation
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.spatial.distance as sd</p>

<p>def centsize(M): #centroid size
  p = M.shape[0]
  csize = np.sqrt(np.sum(M.var(0))*(p-1))
  return csize</p>

<p>def transScale(M):  #translation and scale
  tM = M &ndash; M.mean()
  centSize = centsize(M)
  tM = tM / centSize
  return tM</p>

<p>def mshapr (pdf):  #which is a pandas DataFrame, coordinates and individuals columns
  meanShapes = pd.DataFrame()
  dimen = len(allCoords.individuals.unique())
  for ind in range(0, dimen):</p>

<pre><code>temp = pdf[pdf.individuals != ind]
meanShape = temp.iloc[:,0:2].groupby(temp.iloc[:,2]).mean()
meanShapes = meanShapes.append(meanShape)
</code></pre>

<p>  return meanShapes</p>

<p>coordstest = np.vstack([np.random.uniform(175, 220, 10),   #usual data generation</p>

<pre><code>                    np.random.uniform(175, 220, 10)]).T 
</code></pre>

<p>coords = np.vstack([np.random.multivariate_normal(coordstest[i,:], [[3,0],[0,3]], 200) for i in range(10)])
coordinates = pd.Series((np.arange(0,10).reshape(-1,1)<em>np.ones(200).reshape(1,-1)).flatten()) #coordinates column
individuals = np.tile(np.arange(0,200),10) #individuals column
allCoords = pd.DataFrame(coords, columns = [&lsquo;x&rsquo;,&lsquo;y&rsquo;])
allCoords[&lsquo;coordinates&rsquo;] = coordinates
allCoords[&lsquo;individuals&rsquo;] = individuals
allCoords = allCoords.sort_index(by = [&lsquo;individuals&rsquo;,&lsquo;coordinates&rsquo;])
```
Definition of the </em>pProc<em> function follows the same rules as in the previous post, with the robust (and ugly for now) if clause that is only included to allow either pandas DataFrame or a numpy array as the input data (both for configurations and mean shape objects). It also returns only the rotated matrix, landmark configuration (</em>pmat1*) and not the mean shape.</p>

<p>``` r pProc function for two configuration matrices
def pProc(mat1, mat2): #returning only centred preshape of mat1 on mat2
  if type(mat1) is np.ndarray and type(mat2) is np.ndarray:</p>

<pre><code>k = mat1.shape[1]-1
m = mat1.shape[0]
sscaledMat1 = mat1 / centsize(mat1)
sscaledMat2 = mat2 / centsize(mat2)
z1 = sscaledMat1 - [sscaledMat1[:,0].mean(), sscaledMat1[:,1].mean()]
z2 = sscaledMat2 - [sscaledMat2[:,0].mean(), sscaledMat2[:,1].mean()]
tempSv = np.dot(np.transpose(z2), z1)
svdMat = np.linalg.svd(tempSv)
U = svdMat[0]
V = svdMat[2]
Ds = svdMat[1]
tempSig = np.linalg.det(np.dot(np.transpose(z1), z2))
sig = np.sign(tempSig)
Ds[k] = sig * np.absolute(Ds[k])
U[:,k] = sig * U[:,k]
Gam = np.dot(V, np.transpose(U))
beta = np.sum(Ds)
pmat1 = np.dot(z1, Gam)
pmat1 = pd.DataFrame(pmat1, columns = ['x','y'])
return pmat1
</code></pre>

<p>  else:</p>

<pre><code>mat1x = mat1.iloc[:,0]
mat1y = mat1.iloc[:,1]
mat1 = np.concatenate([mat1x, mat1y], axis = 1).reshape(mat1.shape[1],mat1.shape[0]).T
mat2x = mat2.iloc[:,0]
mat2y = mat2.iloc[:,1]
mat2 = np.concatenate([mat2x, mat2y], axis = 1).reshape(mat2.shape[1],mat2.shape[0]).T
k = mat1.shape[1]-1
m = mat1.shape[0]
sscaledMat1 = mat1 / centsize(mat1)
sscaledMat2 = mat2 / centsize(mat2)
z1 = sscaledMat1 - [sscaledMat1[:,0].mean(), sscaledMat1[:,1].mean()]
z2 = sscaledMat2 - [sscaledMat2[:,0].mean(), sscaledMat2[:,1].mean()]
tempSv = np.dot(np.transpose(z2), z1)
svdMat = np.linalg.svd(tempSv)
U = svdMat[0]
V = svdMat[2]
Ds = svdMat[1]
tempSig = np.linalg.det(np.dot(np.transpose(z1), z2))
sig = np.sign(tempSig)
Ds[k] = sig * np.absolute(Ds[k])
U[:,k] = sig * U[:,k]
Gam = np.dot(V, np.transpose(U))
beta = np.sum(Ds)
pmat1 = np.dot(z1, Gam)
pmat1 = pd.DataFrame(pmat1, columns = ['x','y'])
return pmat1
</code></pre>

<p>```</p>

<p>Finally, the <em>pGP</em> function, that can perform partial Procrustes superimposition for any number of individuals (landmark configurations) and landmarks. Generated data has 200 individuals and 10 2D landmarks. For now this function will ask such information in the function call, so that mmat1 is pandas DataFrame with x, y, coordinates and individuals columns (generated above), numind is the number of individuals, dim is 2D (3D not yet supported), and numland is the number of landmarks. For clearer understanding of the following code, comments are included where appropriate.</p>

<p>``` r Partial Procrustes Superimposition
def pGP (mmat1, numind, dim, numland):
  groupCoords = mmat1.iloc[:,0:2].groupby(mmat1.iloc[:,3])
  transCoords = groupCoords.apply(transScale) #translate and scale the sample data
  individuals = np.tile(np.arange(0,numind),numland)
  coordinates = pd.Series((np.arange(0,numland).reshape(-1,1)<em>np.ones(numind).reshape(1,-1)).flatten())
  transCoords[&lsquo;coordinates&rsquo;] = coordinates
  transCoords[&lsquo;individuals&rsquo;] = np.sort(individuals).astype(str)
  #this part of the code calculates Q-the convergence criterion
  #that is really the sum of the pairwise squared distances between all shapes in the sample
  #so that, after rotation these distances are minimized as much as possible
  arrayx = transCoords.iloc[:,0]
  arrayy = transCoords.iloc[:,1]
  forDist = np.concatenate([arrayx, arrayy], axis = 1).reshape(dim,numland</em>numind).T
  forDist = forDist.reshape(numind, numland*2) #distance function from scipy
  Qm1 = sd.pdist(forDist)
  Q = Qm1.sum()
  while absolute(Q) > 0.00001: #execute the following code until Q cannot be reduced anymore</p>

<pre><code>groupTrans = transCoords.iloc[:,0:2].groupby(transCoords.iloc[:,3])
meanShapes = mshapr(transCoords) #calculate DataFrame of mean shapes excluding one individual at the time
meanShapes['individuals'] = np.sort(individuals).astype(str)
meanGroups = meanShapes.iloc[:,0:2].groupby(meanShapes.iloc[:,2])   
tempRot = pd.DataFrame()
#following for loop performs partial Procrustes superimposition (pProc function from above) between
#mean shapes and each configuration (individual)
for ind in range(0, numind): 
  tosto = pProc(groupTrans.get_group(str(ind)), meanGroups.get_group(str(ind)))
  tempRot = tempRot.append(tosto)
tempX = tempRot.iloc[:,0]
tempY = tempRot.iloc[:,1]
tempDist = np.concatenate([tempX, tempY], axis = 1).reshape(dim,numland*numind).T
tempDist = forDist.reshape(numind, numland*2)
Qm2 = sd.pdist(tempDist)
Q = Qm1.sum() - Qm2.sum()
Qm1 = Qm2 #re-calculate the convergence criterion at each step
transCoords = tempRot
</code></pre>

<p>  return tempRot
```</p>

<p>DataFrame <em>tempRot</em> holds the superimposed configurations (shape variables) that can, subsequently, be used in standard GM analyses and further. Of course, graphical display of superimposition results can be very interesting, and in this post only basic plots will be given, while some of the further posts may include more visualizations. Figure 1 shows the original raw-generated data, Figure 2 the spatial relationships between raw and superimposed data, while Figure 3 shows only superimposed data.</p>

<p>```r Plotting the data and the relationship of raw and superimposed data
procCoords = pGP(allCoords, 200,2,10) #perform superimposition
procoordinates = np.tile(np.arange(0,10),200)
procCoords[&lsquo;coordinates&rsquo;] = procoordinates
meanShape1 = allCoords.iloc[:,0:2].groupby(allCoords.iloc[:,2]).mean() #calculate mean shape for raw data
meanShape1 = pd.DataFrame(polarRotator(np.array(meanShape1))) #natural ordering for landmark labels
plt.scatter(allCoords[&lsquo;x&rsquo;], allCoords[&lsquo;y&rsquo;], s = 30, c = &ldquo;#82CDFF&rdquo;, edgecolors = &lsquo;none&rsquo;) #plot original sampled points
plt.scatter(meanShape1[0], meanShape1[1], s = 50, c = &ldquo;#7909E8&rdquo;, edgecolors = &lsquo;none&rsquo;)
plt.plot(meanShape1[0], meanShape1[1], &lsquo;&ndash;&rsquo;, color = &ldquo;#7909E8&rdquo;)
labels = [&lsquo;Landmark {0}&rsquo;.format(i) for i in range(10)]
for label, x, y in zip(labels, meanShape1[0], meanShape1[1]): #annotate mean landmarks by numbers
  plt.annotate(label, xy = (x, y+0.4),ha = &lsquo;right&rsquo;, va = &lsquo;bottom&rsquo;)
plt.grid()
meanShape2 = procCoords.iloc[:,0:2].groupby(procCoords.iloc[:,2]).mean() #calculate mean shape for superimposed data
meanShape2 = pd.DataFrame(polarRotator(np.array(meanShape2))) #natural ordering for landmark labels
plt.scatter(procCoords[&lsquo;x&rsquo;], procCoords[&lsquo;y&rsquo;], s = 30, c = &ldquo;#FFD699&rdquo;, edgecolors = &lsquo;none&rsquo;)
plt.scatter(meanShape2[0], meanShape2[1], s = 50, c = &ldquo;#7909E8&rdquo;, edgecolors = &lsquo;none&rsquo;)
plt.plot(meanShape2[0], meanShape2[1], &lsquo;&ndash;&rsquo;, color = &ldquo;#7909E8&rdquo;)
for label, x, y in zip(labels, meanShape2[0], meanShape2[1]): #annotate mean landmarks by numbers
  plt.annotate(label, xy = (x, y+0.01),ha = &lsquo;right&rsquo;, va = &lsquo;bottom&rsquo;)
plt.grid()</p>

<h1>for Figure 2 just plt.scatter of both allCoords and procCoords in the same window</h1>

<p>```
<img class="center" src="/images/rawWithout.png" width="650" height="484" title="&lsquo;raw generated landmark data&rsquo;" >
<img class="center" src="/images/originalSuperimposed.png" width="650" height="484" title="&lsquo;original vs superimposed&rsquo;" >
<img class="center" src="/images/superWith.png" width="650" height="481" title="&lsquo;superimposed landmark data&rsquo;" ></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>If using IPython (:)) best way is to paste code with the %paste magic function.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modularity, Graphs and Triangulations]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/05/03/modularity-graphs-and-triangulations/"/>
    <updated>2014-05-03T00:08:25+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/05/03/modularity-graphs-and-triangulations</id>
    <content type="html"><![CDATA[<p>Continuing on the previous post, procedures presented here show the comparison between the usual assesment of modularity in the collection of landmarks (same dataset as before) and the depiction of modular structure through graph theory. Usually, modularity in the mammalian cranium is determined a-priori, according to some of the established hypotheses about the developmental origin of cranial elements. One of the most prevalent hypotheses is the two-module organization, one module comprising of elements originating mainly from the neural crest embryonic tissue (anterior cranium) and one comprising of elements with somitomeric origin (posterior cranium). Following code shows the test of this specific hypothesis using <em>geomorph</em> package functions, and additional usage of <em>deldir</em> for visualization of modularity hypotheses.</p>

<p>```r Importing data, basic GM, modularity and plots
library(geomorph)
library(deldir)
library(ggplot2)
load(&ldquo;capSample.RData&rdquo;)
theme_set(theme_bw())</p>

<p>capGPA &lt;&ndash; gpagen(capSample)
capCoords &lt;&ndash; capGPA$coords
mshapeCap &lt;&ndash; mshape(capCoords) #mean shape is useful for plotting</p>

<h1>vector depicting the division of landmarks according to modularity</h1>

<p>modularity1.gps &lt;&ndash; c(&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;A&rdquo;,&ldquo;B&rdquo;,&ldquo;B&rdquo;,&ldquo;A&rdquo;,&ldquo;B&rdquo;,&ldquo;B&rdquo;,&ldquo;B&rdquo;,&ldquo;B&rdquo;,&ldquo;B&rdquo;)</p>

<h1>test for modularity based on the RV coefficient</h1>

<p>modularity1 &lt;&ndash; compare.modular.partitions(capCoords, landgroups = modularity1.gps)</p>

<h1>plot of landmark membership to a-priori modules</h1>

<p>deldir(mshapeCap[,1], mshapeCap[,2], plotit = TRUE, wlines = &ldquo;triang&rdquo;, xlim = c(-0.2,0.55))
points(mshapeCap[c(1:8,11),1], mshapeCap[c(1:8,11),2], col = &ldquo;#FF8740&rdquo;, pch = 19, cex = 1.2)
points(mshapeCap[c(9,10,12:16),1], mshapeCap[c(9,10,12:16),2], col = &ldquo;#61B4CF&rdquo;, pch = 19, cex = 1.2)
legend(0.2,0.4, legend = c(&ldquo;neural crest&rdquo;, &ldquo;somitomere&rdquo;), fill = colormap)
```</p>

<p>Figure 1 shows the theoretical distribution of the RV coefficients, calculated for all posible two-module subdivisions of landmarks, as well as the observed RV value from the hypothesis depicted in Figure 2. Since the observed value is lower than most of the hypothetic values, then it could be said that this modularity hypothesis stands.</p>

<p><img class="center" src="/images/RVmodularity.png" width="570" height="497" title="&lsquo;RV coefficients&rsquo;" >
<img class="center" src="/images/modularityLand.png" width="344" height="376" title="&lsquo;Modularity hypothesis&rsquo;" ></p>

<p>The idea for using graph theory representation and analysis of modularity is based on correlation matrix, same one from the previous post. Correlation matrix was obtained through Delaunay triangulation and every vertex (node) in the graph actually represents the 1/3 of the total area of all Delaunay triangles emanating from the corresponding landmark.</p>

<p><code>r Delaunay triangulation and derivation of the correlation matrix
cicoCap &lt;- t(apply(capCoords, 3, function(A) deldir(A[,1],A[,2])$summary[,4]))
cicoCap &lt;- data.frame(cicoCap)
names(cicoCap) &lt;- paste("lm", c(1:16), sep = "")
capCor &lt;- abs(cor(cicoCap)) #correlation matrix
diag(capCor) &lt;- 0 #diagonals must be set to zero
</code></p>

<p>Graph based on the correlation matrix can be created and manipulated with the wonderful <em>igraph</em> package. Vertices of this graph will be abovementioned areas, while the edges will represent correlation (edge weights) between areas around each landmark. According to weights, edges can be colored and the strength of thier lines increased, so that the most correlated landmarks wolud be more obvious.</p>

<p><code>r iGraph graph creation and manipulation
graph &lt;- graph.adjacency(capCor, weighted=TRUE, mode="upper")
E(graph)[ weight &gt; 0.5 ]$color &lt;- "#A63E00"
E(graph)[ weight &gt; 0.5 ]$width &lt;- 3.6
E(graph)[ weight &gt; -0.5 &amp; weight &lt; 0.5 ]$color &lt;- "#D6EBFF"
E(graph)[ weight &gt; -0.5 &amp; weight &lt; 0.5 ]$width &lt;- 1.2
</code></p>

<p>Modularity, or community structure in the graph theory represents the degree of compartmentalization in the graph structure, based on the spatial relationship or the weights of graph edges. Although, a-priori subdivision of graph vertices is possible, and the evaluation of such graph community can be easily done, the advantage of graph theory for modularity is the availability of algorithms for searching the community structure, so it can derive subdivsion a-posteriori, that can be compared to the hypothesis from Figure 1.</p>

<p>```r Graph modularity and plotting
gsc &lt;&ndash; leading.eigenvector.community(graph, weights = E(graph)$weights)
modularity(graph, membership(gsc))
colormap &lt;&ndash; c(&ldquo;#FF8740&rdquo;, &ldquo;#61B4CF&rdquo;)
V(graph)$color &lt;&ndash; colormap[gsc$membership] #color graph vertices according to community</p>

<h1>graph layout will be circular since values for the edges range from 0.2 to 0.9,</h1>

<h1>and they all form similar attractive force between the vertices.</h1>

<p>graph$layout &lt;&ndash; layout.fruchterman.reingold #really no effect on the shape of this graph</p>

<p>plot(graph, vertex.size = 20, vertex.shape = &ldquo;circle&rdquo;)
legend(0.8,1.4, legend = c(&ldquo;neural crest&rdquo;, &ldquo;somitomere&rdquo;), fill = colormap)
```</p>

<p>Leading eigenvector community algorithm tries to find community structure in the graph by calculating the eigenvector of the modularity matrix for the largest positive eigenvalue and then separating vertices into two communities based on the sign of the corresponding element in the eigenvector (Newman, 2006<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>). This method was preffered over many others because it is closer to usual multivariate methods, such as PCA, that are commonly used to depict variability patterns.</p>

<p><img class="center" src="/images/modularityGraph.png" width="541" height="467" title="&lsquo;Modularity graph&rsquo;" ></p>

<p>Graph community strucure depicts modularity in the landmark configurations accurately, with the exception of lm16, that is positioned on the posterior basicranium. Higher correlations are, on average, present within modules while between modules, only one connection is higher than 0.5, that between lm2 and lm14. Since these landmarks lay on the opposite sides of the cranium, they may encompass the variability in total anterior-posterior length. i.e. cranial size.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Newman, M.E.J. 2006. Modularity and community structure in networks. <em>PNAS</em> <strong>103</strong>: 8577-8582.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
