<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Utilities | Creative morphometrics]]></title>
  <link href="http://paulidealiste.github.io/blog/categories/utilities/atom.xml" rel="self"/>
  <link href="http://paulidealiste.github.io/"/>
  <updated>2015-01-19T20:57:22+01:00</updated>
  <id>http://paulidealiste.github.io/</id>
  <author>
    <name><![CDATA[Miloš Blagojević]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Efficient Outlines Around Points in R]]></title>
    <link href="http://paulidealiste.github.io/blog/2015/01/18/efficient-outlines-around-points-in-r/"/>
    <updated>2015-01-18T10:25:19+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2015/01/18/efficient-outlines-around-points-in-r</id>
    <content type="html"><![CDATA[<p>Convex hull is one of the most widely used techniques for finding the minimum enclosing shape around a set of points in a plane, but for certain tasks it is necessery to find such shape which encloses concave parts of the outline as well. Convex hulls are also sensitive to localized point groups, far apart from the majority of other points. In these cases, hulls enclose a lot of empty space so that the possible underlining shape is obscured. In geometric morphometrics, outlines around the set of landmarks in the plane can provide the idea of shape, useful for visualization of the underlining shape (i.e. the shape described by these points). Possibly, such outlines may be analysed further, with the usual GM analytic procedures. Alpha shape<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> is the generalization of the convex hull for a set of points in the plane which can be used for shape reconstruction, since the frontier of an alpha shape is a linear approximation of the original shape. In R, this technique is implemented in the <em>alphahull</em> library. For this post, randomly generated points-in-the-plane data will be used.</p>

<p><code>r Generating data and loading the library
library(alphahull)
sampleData &lt;- data.frame(x=runif(30, 10, 50), y=runif(30,10,50)) #with uniform number generators
</code></p>

<p>For a set of points, alpha shape is based on the Delaunay triangulation and its corresponding Voronoi diagram, so they are found first, followed by alpha shape and alpha hull.</p>

<p><code>r Calculating Delaunay triangulation, Voronoi diagram and alpha shape of the sample data
sampleDel &lt;- delvor(sampleData) #Delaunay/Voronoi
sampleAlpha &lt;- ashape(sampleData, alpha = 9) #Alpha shape
</code>
The value of the parameter alpha is determined with respect to the dimensionality of data points, since it represents the minimal distance for icnlusion or exclusion of the neighbouring points within the alpha shape procedure.</p>

<p><code>r Plotting of the corresponding shapes
plot(sampleDel, col=c(1, "darkturquoise", "grey80",1), lwd = c(2,2), cex = 0.1, xlab = NA, ylab = NA)
points(sampleData, col = "darkorange", pch = 16, cex = 1.5) #Plot of the Delaunay
plot(sampleAlpha, wlines = "del", col = c("goldenrod4",1, "darkturquoise"), lwd = c(2,4), cex = 0.1, xlab = NA, ylab = NA)
points(sampleData, col = "darkorange", pch = 16, cex = 1.3) #Plot of the alpha shape
</code>
When the value of alpha is selected taking into account the spacing between the points, the enclosing outline can be obtained so that it approximates the most probable shape of the points in the plane (Figure 1, Figure 2).</p>

<p><img class="center" src="/images/Originalanddelaunay.png" width="640" height="275" title="&lsquo;Random points Delaunay Voronoi&rsquo;" >
<img class="center" src="/images/borderingalpha.png" width="640" height="275" title="&lsquo;Random points Bordering alphashape&rsquo;" ></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Edelsbrunner, H., Kirkpatrick, D.G. and R. Seidel. 1983. On the shape of a set of points in the plane. <em>IEEE Transactions on information theory</em>, <strong>29</strong>: 551-559.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PLS Model for Temperature in R]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/09/02/pls-model-for-temperature-in-r/"/>
    <updated>2014-09-02T13:01:59+02:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/09/02/pls-model-for-temperature-in-r</id>
    <content type="html"><![CDATA[<p>Continuing on the post about the climate data extraction in R, this post demonstrates a simple approach to using PLS (partial least squares) for determining the common covariance patterns between morphology and mean monthly temperature (although the model is likely to be bad). Morphology data can be found  <a href = "http://goo.gl/7BQ4tT"> here</a>. This dataset only contains PCA scores of individuals for the first two PC axes (Figure 1), extracted from the Fourier descriptors of horn shape. PC1 axis (92%) clearly separates males and females on the basis of respective horn shape.</p>

<p><img class="center" src="/images/pca1plot.png" width="450" height="393" title="&lsquo;ordinary PCA&rsquo;" ></p>

<p>Temperature data are extracted using geoTiffs from  <a href="http://www.worldclim.org/" target="_blank">WorldClim</a> database, as in the mentioned post about climate data extraction. The ready-made dataset of mean monthly temperatures for the above study locality can be found <a href = "http://goo.gl/2fAlAF"> here</a>.</p>

<p>```r Importing data and plotting the Figure 1 PCA
fourierPC &lt;&ndash; read.table(&ldquo;~/fourierPC.txt&rdquo;, header = TRUE, sep = &ldquo;,&rdquo;) #by default they are in the home directory
matTaraMean &lt;&ndash; read.table(&ldquo;~/matTaraMean.txt&rdquo;, header = TRUE, sep = &ldquo;,&rdquo;)</p>

<p>library(ggplot2)
theme_set(theme_bw())
sex &lt;&ndash; c(&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;, &ldquo;m&rdquo;,&ldquo;m&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;,&ldquo;f&rdquo;,&ldquo;m&rdquo;,&ldquo;f&rdquo;) #individual sex is known in advance
ggplot(fourierPC, aes(PC1, PC2)) + geom_point(size = 5, shape = 19, aes(color = sex))
```
PLS analysis is a useful multivariate technique used for determining the common variation patterns in two blocks of data and is sometimes reffered to as PLS regression. In this post, of all PLS implementations in R, the choice is on the fabulous <em>plsdepot</em> library, developed and maintained by Gaston Sanchez, whose <a href="http://gastonsanchez.com" target="_blank"> blog/personal page</a> and work in general was a great insipiration for Creative Morphometrics. His approach is very well explained and documented over at his page, so only direct implementation on the data above will be provided here.</p>

<p><code>r PLS plsdepot library
library(plsdepot)
taraMat &lt;- matTaraMean[sample(221, 26),] #extract 26 samples from 221 raster grid values
climatePLS &lt;- plsreg1(taraMat, fourierPC$PC1, comps = 3)
plot(climatePLS)#plot circle of correlations in order to determine the influence of predictor variables
</code></p>

<p><img class="center" src="/images/RplotCircles.png" width="450" height="393" title="&lsquo;PLS correlation circle&rsquo;" ></p>

<p>It is obvious from Figure 2. that the variables in question share no common variation pattern and are totally unrelated. If the chosen data was better, some of the blue lines (predictors) would run parallel with the orange one (response). If the R<sup>2</sup> value for this model is examined (it is a part of climatePLS object &ndash; climatePLS$R2) the unrelatedness of predictors and response in this model gets even more obvious (R<sup>2</sup> = 0.035). Predictors in this model are also highly correlated within themselves, which renders them rather useles in prediction, as was stated at the onset.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Extracting Climate Data in R]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/03/27/extracting-climate-data-in-r/"/>
    <updated>2014-03-27T19:44:55+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/03/27/extracting-climate-data-in-r</id>
    <content type="html"><![CDATA[<p>With the ongoing expand of the available geospatial databases in raster format (GeoTiff) it is getting easier to analyse the relationship between any complex morphology, captured in landmark data, and i.e. climate or precipitation data with the help of partial least squares (PLS). R has a wonderful <em>raser</em>, <em>sp</em> and <em>gdal</em> packages that facilitate the extraction of the geospatial data from GeoTiff raster grids. In this post the geoTiff used will be from the <a href="http://www.worldclim.org/" target="_blank">WorldClim</a> website, and the climate data for European square 16, where some of my real samples originate from. In order to get this data you can follow the downloads section of the WorldClim website and choose download data by tile, 30 arc-seconds resolution. When a map opens the dataset for this post would be under the map, when clicked on the square zone 16 and finally download the Mean Temperature. This is a .zip file with twelve GeoTiffs, one for each month. Unpack the files in a pre-destined directory, and declare this a working directory in the R session.
<code>r Importing libraries, reading and inital plots of the GeoTiff data
setwd("~/tmean") #this is the folder with all the GeoTiffs
library(raster)
library(sp)
library(rgdal)
meanJan &lt;- raster("tmean1_16.tif") #mean temp for January etc.
meanFeb &lt;- raster("tmean2_16.tif")
meanMar &lt;- raster("tmean3_16.tif")
meanApr &lt;- raster("tmean4_16.tif")
meanMaj &lt;- raster("tmean5_16.tif")
meanJun &lt;- raster("tmean6_16.tif")
meanJul &lt;- raster("tmean7_16.tif")
meanAvg &lt;- raster("tmean8_16.tif")
meanSep &lt;- raster("tmean9_16.tif")
meanOkt &lt;- raster("tmean10_16.tif")
meanNov &lt;- raster("tmean11_16.tif")
meanDec &lt;- raster("tmean12_16.tif")
plot(meanJan) #will simply get the basic R plot of a GeoTiff raster
</code>
<img class="center" src="/images/meanJan.png" width="521" height="410" title="&lsquo;mean january&rsquo;" ></p>

<p>After reading in the basic data, <em>raster</em> package offers several formats in which to keep the data, besides the basic raster. The most useful one is a raster stack which really is just the piled-up rasters that can be manipulated together. Also one useful visual help is the addition of the country boundaries followed by zooming in to the extent of the country or region where the samples originate from. Country boundaries .shp files is freely avalilable from <a href="http://thematicmapping.org/downloads/world_borders.php" target="_blank">thematicmapping</a>. When downloaded they should be in the same directory as the GeoTiffs.</p>

<p>```r Creating the raster stack, adding boundaries and zooming to an extent
mtStack &lt;&ndash; stack(meanJan, meanFeb, meanMar, meanApr, meanMaj, meanJun, meanJul, meanAvg, meanSep, meanOkt, meanNov, meanDec)
bounds &lt;&ndash; readOGR(dsn=getwd(), layer= &ldquo;TM_WORLD_BORDERS-0.3&rdquo;) #import borders
plot(meanJan) #plot the raster file for any month
extentR &lt;&ndash; drawExtent()</p>

<h1>drawExtent enters the interactive mode where you can draw the polygon for zooming based on two points, top right and lower left</h1>

<h1>values in extentR are coordinates in WGS84 datum and expressed as longitude data</h1>

<p>plot(zoom(bounds, extentR), add = TRUE)</p>

<h1>unfortunately this does not work well since it will plot the bounds in the zoom extent</h1>

<h1>and if the both raster and bounds are needed then it might be ok to overlap them in GIMP</h1>

<p>plot(zoom(meanJan, extentR), add = TRUE)
```
<img class="center" src="/images/zoomara.png" width="519" height="414" title="&lsquo;mean january zoomed&rsquo;" ></p>

<p>Before final extraction of the climate data it can be useful to plot each month`s mean temperature for the selected extent of the rasater. This can be easily achieved by using the <em>rasterVis</em> package levelplot and the extentR variable, which can be used to cut through all raster layers in the stack.</p>

<p>```r Cutting the stack and drawing levelplot for all months
library(rasterVis)
cutStack &lt;&ndash; (crop(mtStack, extentR))/10</p>

<h1>division by 10 is needed since the temperature data in this GeoTiff is x10 for saving memory-important</h1>

<p>names(cutStack) &lt;&ndash; month.abb
levelplot(cutStack) #may take long time to plot
histogram(cutStack)
```
<img class="center" src="/images/meanLevel1.png" width="570" height="467" title="&lsquo;mean all&rsquo;" >
<img class="center" src="/images/meanLevel2.png" width="570" height="467" title="&lsquo;mean all h&rsquo;" ></p>

<p>Slightly more efficient than the drawExtent is the spatialPolygons function from the <em>sp</em> package that will be used for definition of the real sampling localities, by simply drawing boundaries of the localities by hand or using the known positional data. It is best if approximate latitude/longitude coordinates are known in advance so that the defining polygon can be drawn connecting several corners-points, that form the broader sampling area border. If coordinates are not known in advance then the drawExtent should be used first for finding the latitude/longitude of the spatial polygon points, and then making the SpatialPolygon object out of them, as described next.</p>

<p>```r Extracting spatialPolygons by latitude/longitude pairs
taraCoord &lt;&ndash; rbind(c(19.241867, 44.012571), c(19.351730, 43.976511), c(19.518585, 43.923121), c(19.435501, 43.894924), c(19.317398, 43.896903), c(19.261780, 43.955259), c(19.241867, 44.012571))
R1Coord &lt;&ndash; rbind(c(24.656067, 45.627484), c(25.252075, 45.575600), c(25.628357, 45.525592), c(25.488281, 45.3000007), c(25.046082, 45.381080), c(24.672546, 45.539060), c(24.656067, 45.627484))</p>

<h1>these objects are matrices with two columns, one for latitude of a polygon corner and the other the longitude</h1>

<p>polyTara &lt;&ndash; SpatialPolygons(list(Polygons(list(Polygon(taraCoord)), 1))) #declare object type
polyR1 &lt;&ndash; SpatialPolygons(list(Polygons(list(Polygon(R1Coord)), 1)))
<code>``
After all spatial polygons are defined, final step involves the extraction of the mean temperature values from the points encircled by the polygon in question, for all months. Since GeoTiffs are raster formats, they are carrying the information on the temperature in the points of the bitmap grid, so if the polygon is too small, small will be the number of the grid-points inside, maybe smaller than the number of individuals. To avoid this make sampling area broader, and in this case polyTara has some 220 individual grid points inside, which means 220 values for the mean temperature in the area. If we have i.e. ten individuals per population it is necessery to have also 10 mean temperature values, so that both blocks in subsequent PLS would have same dimensionality. R</code>s basic sample function can be used to extract random values from the i.e. 220 points within the population (Tara and R1) polygons. This simulates random sampling of individuals from the sampling locality and after that any analysis can be done, from linear models to PLS, which will be shown in future posts.</p>

<p><code>r Extracting climate data and preparing the dataset according to the number of individuals
matTaraMean &lt;- extract(cutStack, polyTara)[[1]]
matR1Mean &lt;- extract(cutStack, polyR1)[[1]]
plot(cutStack$Jan)
plot(polyTara, add = TRUE)
plot(polyR1, add = TRUE)
n &lt;- dim(matTaraMean)[1] #for sampling convenience
m &lt;- dim(matR1Mean)[1]
taraMat &lt;- matTaraMean[sample(n, 10),] #this is the final extracted data
R1Mat &lt;- matR1Mean[sample(m, 10),]
library(ggplot2)
library(reshape2)
plotter &lt;- data.frame(rbind(taraMat, R1Mat), loc = c(rep("Ta",10), rep("R1", 10))) #for ggplot2
forplo &lt;- melt(plotter)
m &lt;- ggplot(forplo, aes(x = value, fill = loc)) + geom_histogram() + facet_grid(variable~.)
</code></p>

<p>Figure 5. shows the locations of tara and R1 spatial polygons within the zoomed extent of the zone 16, while in Figure 6. barplots are shown for 10 random points for all months, and for both localities, for comparison.</p>

<p><img class="center" src="/images/Fig5climate.png" width="536" height="433" title="&lsquo;localities&rsquo;" >
<img class="center" src="/images/Fig6climate.png" width="802" height="700" title="&lsquo;histograms&rsquo;" ></p>

<p>It is obvious that the Tara locality has higer mean monthly temperature, on average for every month, and also it has less temperature variaton than R1.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[XY Outlines in GIMP and imageJ]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/02/01/xy-outlines-in-gimp-and-imagej/"/>
    <updated>2014-02-01T11:23:55+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/02/01/xy-outlines-in-gimp-and-imagej</id>
    <content type="html"><![CDATA[<p>This post continues on the first post about outline deformations and presents a simple way for generating outlines as XY data. XY format is very convenient for representing outline and line art in R or python. This type of visualization can be produced using <a href="http://www.gimp.org" target="_blank">GIMP</a> and <a href="http://rsbweb.nih.gov/ij" target="_blank">imageJ</a> through a sequence of easy steps. GIMP enables easy extraction of the central object from the image background. First step in outline extraction should be the precise definition of the object boundaries, such that the contrast between the object and the background is maximal. Example picture for this post is available <a href="http://goo.gl/bkirX7" target="_blank">here</a>. After opening the picture in GIMP workspace it looks like in Figure 1.</p>

<p><img src="/images/Gimp1.png" width="375" height="289" title="&lsquo;Gimp import&rsquo;" > <img class="right" src="/images/Gimp2.png" width="375" height="290" title="&lsquo;Gimp scissors&rsquo;" ></p>

<p>The easiest way to separate this chamois cranium from its background is to use <code>Scissor Select Tool</code> from the GIMP toolbox. This tool can nicely track the path between sucessive control points that should be placed along the desired object (Figure 2). When control points are placed along the shape, selection can be completed by pressing enter, and the background can be deleted by inverting selection pressing <code>Ctrl+I</code>. and deleting it using the delete key (Figure 3). Selection should be inverted once more and converted to path; from the <code>Select</code> menu <code>To Path</code>. Finally, stroke path (Figure 4, path card and right click on selection, <code>Stroke path</code>) gives the desired outline that can be exported as .tiff for imageJ through <code>Export</code> in the <code>File</code> menu.</p>

<p><img src="/images/Gimp3.png" width="375" height="290" title="&lsquo;Gimp no background&rsquo;" > <img class="right" src="/images/Gimp4.png" width="375" height="289" title="&lsquo;Gimp stroke path&rsquo;" ></p>

<p>In imageJ, picture should be converted to binary in <code>Process</code> menu, by selecting <code>Binary</code> and <code>Make Binary</code>. Final step is saving the binary image selection as XY data. First the outline should be selected by the magic wand selection tool (Figure 5) and then the image should be saved in XY format, in <code>File</code> menu, <code>Save as</code> and select <code>XY coordinates</code>. The XY data is also available <a href="http://goo.gl/d44PxK" target="_blank">here</a>.</p>

<p><img src="/images/GimpNo.png" width="310" height="326" title="&lsquo;imageJ&rsquo;" ></p>

<p>Now the .txt file could be easily imported into R and python.</p>
]]></content>
  </entry>
  
</feed>
