<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: R | Creative morphometrics]]></title>
  <link href="http://paulidealiste.github.io/blog/categories/r/atom.xml" rel="self"/>
  <link href="http://paulidealiste.github.io/"/>
  <updated>2014-03-28T00:22:16+01:00</updated>
  <id>http://paulidealiste.github.io/</id>
  <author>
    <name><![CDATA[Miloš Blagojević]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Extracting Climate Data in R]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/03/27/extracting-climate-data-in-r/"/>
    <updated>2014-03-27T19:44:55+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/03/27/extracting-climate-data-in-r</id>
    <content type="html"><![CDATA[<p>With the ongoing expand of the available geospatial databases in raster format (GeoTiff) it is getting easier to analyse the relationship between any complex morphology, captured in landmark data, and i.e. climate or precipitation data with the help of partial least squares (PLS). R has a wonderful <em>raser</em>, <em>sp</em> and <em>gdal</em> packages that facilitate the extraction of the geospatial data from GeoTiff raster grids. In this post the geoTiff used will be from the <a href="http://www.worldclim.org/" target="_blank">WorldClim</a> website, and the climate data for European square 16, where some of my real samples originate from. In order to get this data you can follow the downloads section of the WorldClim website and choose download data by tile, 30 arc-seconds resolution. When a map opens the dataset for this post would be under the map, when clicked on the square zone 16 and finally download the Mean Temperature. This is a .zip file with twelve GeoTiffs, one for each month. Unpack the files in a pre-destined directory, and declare this a working directory in the R session.
<code>r Importing libraries, reading and inital plots of the GeoTiff data
setwd("~/tmean") #this is the folder with all the GeoTiffs
library(raster)
library(sp)
library(rgdal)
meanJan &lt;- raster("tmean1_16.tif") #mean temp for January etc.
meanFeb &lt;- raster("tmean2_16.tif")
meanMar &lt;- raster("tmean3_16.tif")
meanApr &lt;- raster("tmean4_16.tif")
meanMaj &lt;- raster("tmean5_16.tif")
meanJun &lt;- raster("tmean6_16.tif")
meanJul &lt;- raster("tmean7_16.tif")
meanAvg &lt;- raster("tmean8_16.tif")
meanSep &lt;- raster("tmean9_16.tif")
meanOkt &lt;- raster("tmean10_16.tif")
meanNov &lt;- raster("tmean11_16.tif")
meanDec &lt;- raster("tmean12_16.tif")
plot(meanJan) #will simply get the basic R plot of a GeoTiff raster
</code>
<img class="center" src="/images/meanJan.png" width="521" height="410" title="&lsquo;mean january&rsquo;" ></p>

<p>After reading in the basic data, <em>raster</em> package offers several formats in which to keep the data, besides the basic raster. The most useful one is a raster stack which really is just the piled-up rasters that can be manipulated together. Also one useful visual help is the addition of the country boundaries followed by zooming in to the extent of the country or region where the samples originate from. Country boundaries .shp files is freely avalilable from <a href="http://thematicmapping.org/downloads/world_borders.php" target="_blank">thematicmapping</a>. When downloaded they should be in the same directory as the GeoTiffs.</p>

<p>```r Creating the raster stack, adding boundaries and zooming to an extent
mtStack &lt;&ndash; stack(meanJan, meanFeb, meanMar, meanApr, meanMaj, meanJun, meanJul, meanAvg, meanSep, meanOkt, meanNov, meanDec)
bounds &lt;&ndash; readOGR(dsn=getwd(), layer= &ldquo;TM_WORLD_BORDERS-0.3&rdquo;) #import borders
plot(meanJan) #plot the raster file for any month
extentR &lt;&ndash; drawExtent()</p>

<h1>drawExtent enters the interactive mode where you can draw the polygon for zooming based on two points, top right and lower left</h1>

<h1>values in extentR are coordinates in WGS84 datum and expressed as longitude data</h1>

<p>plot(zoom(bounds, extentR), add = TRUE)</p>

<h1>unfortunately this does not work well since it will plot the bounds in the zoom extent</h1>

<h1>and if the both raster and bounds are needed then it might be ok to overlap them in GIMP</h1>

<p>plot(zoom(meanJan, extentR), add = TRUE)
```
<img class="center" src="/images/zoomara.png" width="519" height="414" title="&lsquo;mean january zoomed&rsquo;" ></p>

<p>Before final extraction of the climate data it can be useful to plot each month`s mean temperature for the selected extent of the rasater. This can be easily achieved by using the <em>rasterVis</em> package levelplot and the extentR variable, which can be used to cut through all raster layers in the stack.</p>

<p>```r Cutting the stack and drawing levelplot for all months
library(rasterVis)
cutStack &lt;&ndash; (crop(mtStack, extentR))/10</p>

<h1>division by 10 is needed since the temperature data in this GeoTiff is x10 for saving memory-important</h1>

<p>names(cutStack) &lt;&ndash; month.abb
levelplot(cutStack) #may take long time to plot
histogram(cutStack)
```
<img class="center" src="/images/meanLevel1.png" width="570" height="467" title="&lsquo;mean all&rsquo;" >
<img class="center" src="/images/meanLevel2.png" width="570" height="467" title="&lsquo;mean all h&rsquo;" ></p>

<p>Slightly more efficient than the drawExtent is the spatialPolygons function from the <em>sp</em> package that will be used for definition of the real sampling localities, by simply drawing boundaries of the localities by hand or using the known positional data. It is best if approximate latitude/longitude coordinates are known in advance so that the defining polygon can be drawn connecting several corners-points, that form the broader sampling area border. If coordinates are not known in advance then the drawExtent should be used first for finding the latitude/longitude of the spatial polygon points, and then making the SpatialPolygon object out of them, as described next.</p>

<p>```r Extracting spatialPolygons by latitude/longitude pairs
taraCoord &lt;&ndash; rbind(c(19.241867, 44.012571), c(19.351730, 43.976511), c(19.518585, 43.923121), c(19.435501, 43.894924), c(19.317398, 43.896903), c(19.261780, 43.955259), c(19.241867, 44.012571))
R1Coord &lt;&ndash; rbind(c(24.656067, 45.627484), c(25.252075, 45.575600), c(25.628357, 45.525592), c(25.488281, 45.3000007), c(25.046082, 45.381080), c(24.672546, 45.539060), c(24.656067, 45.627484))</p>

<h1>these objects are matrices with two columns, one for latitude of a polygon corner and the other the longitude</h1>

<p>polyTara &lt;&ndash; SpatialPolygons(list(Polygons(list(Polygon(taraCoord)), 1))) #declare object type
polyR1 &lt;&ndash; SpatialPolygons(list(Polygons(list(Polygon(R1Coord)), 1)))
<code>``
After all spatial polygons are defined, final step involves the extraction of the mean temperature values from the points encircled by the polygon in question, for all months. Since GeoTiffs are raster formats, they are carrying the information on the temperature in the points of the bitmap grid, so if the polygon is too small, small will be the number of the grid-points inside, maybe smaller than the number of individuals. To avoid this make sampling area broader, and in this case polyTara has some 220 individual grid points inside, which means 220 values for the mean temperature in the area. If we have i.e. ten individuals per population it is necessery to have also 10 mean temperature values, so that both blocks in subsequent PLS would have same dimensionality. R</code>s basic sample function can be used to extract random values from the i.e. 220 points within the population (Tara and R1) polygons. This simulates random sampling of individuals from the sampling locality and after that any analysis can be done, from linear models to PLS, which will be shown in future posts.</p>

<p><code>r Extracting climate data and preparing the dataset according to the number of individuals
matTaraMean &lt;- extract(cutStack, polyTara)[[1]]
matR1Mean &lt;- extract(cutStack, polyR1)[[1]]
plot(cutStack$Jan)
plot(polyTara, add = TRUE)
plot(polyR1, add = TRUE)
n &lt;- dim(matTaraMean)[1] #for sampling convenience
m &lt;- dim(matR1Mean)[1]
taraMat &lt;- matTaraMean[sample(n, 10),] #this is the final extracted data
R1Mat &lt;- matR1Mean[sample(m, 10),]
library(ggplot2)
library(reshape2)
plotter &lt;- data.frame(rbind(taraMat, R1Mat), loc = c(rep("Ta",10), rep("R1", 10))) #for ggplot2
forplo &lt;- melt(plotter)
m &lt;- ggplot(forplo, aes(x = value, fill = loc)) + geom_histogram() + facet_grid(variable~.)
</code></p>

<p>Figure 5. shows the locations of tara and R1 spatial polygons within the zoomed extent of the zone 16, while in Figure 6. barplots are shown for 10 random points for all months, and for both localities, for comparison.</p>

<p><img class="center" src="/images/Fig5climate.png" width="536" height="433" title="&lsquo;localities&rsquo;" >
<img class="center" src="/images/Fig6climate.png" width="802" height="700" title="&lsquo;histograms&rsquo;" ></p>

<p>It is obvious that the Tara locality has higer mean monthly temperature, on average for every month, and also it has less temperature variaton than R1.</p>

<div id="disqus_thread"></div>


<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'creativemorphometrics'; // required: replace example with your forum shortname
/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>


<p><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[R Generator and a Colorful PCA]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/02/23/r-generator-and-a-colorful-pca/"/>
    <updated>2014-02-23T11:24:16+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/02/23/r-generator-and-a-colorful-pca</id>
    <content type="html"><![CDATA[<p>As simple as it may seem, sample data generation is not a trivial task, especially when random landmarks are to be generated. Usually, one would use multivariate normal distribution-based generator (like mvrnorm in R`s MASS package) in order to generate correlated data. The following function was used to generate data similar to the real world datased, unfortunately based directly on it, by using the coefficients from regressions between successive columns in a data matrix, which represent landmark coordinates in XY data matrix. The following function uses <a href="http://goo.gl/ijI1kn" target="_blank">this</a> data matrix (446 individuals and 28 landmarks), and performs regressions between X-Y pairs for all coordinates. Finally it uses intercepts and slopes to infer mean and SD for rnorm function, random number generator.</p>

<p>```r Resampler function for random resamples of a real data matrix</p>

<p>resampler &lt;&ndash; function(mat) #simulations based on rnorm random sampling
{
  x &lt;&ndash; dim(mat)[1]
  y &lt;&ndash; dim(mat)[2]
  indexrow &lt;&ndash; c(2:x)
  combinations &lt;&ndash; matrix(c(1:y,2:y), ncol = 2) #ignore the warning message
  slope &lt;&ndash; numeric(y)
  intercept &lt;&ndash; numeric(y)
  sds &lt;&ndash; numeric(y)
  for(i in 1:y)
  {</p>

<pre><code>veca &lt;- mat[,combinations[i,]][,1]
vecb &lt;- mat[,combinations[i,]][,2]
model &lt;- lm(veca~vecb)
slope[i] &lt;- coef(model)[2]
intercept[i] &lt;- coef(model)[1]
sds[i] &lt;- sd(mat[,combinations[i,]][,1])
</code></pre>

<p>  }
  coefs &lt;&ndash; data.frame(intercept,slope,sds)
  cexox &lt;&ndash; data.frame(c(1:x))
  for (i in 1:y)
  {</p>

<pre><code>dataCol &lt;- rnorm(length(mat[,combinations[i,]][,2]),mean=intercept[i]+slope[i]*mat[,combinations[i,]][,2],sd=sds)
cexox &lt;- cbind(cexox, dataCol)
</code></pre>

<p>  }
  sampleMatrix &lt;&ndash; as.matrix(cexox)
  sampleMatrix &lt;&ndash; sampleMatrix[,-1]
  return(sampleMatrix)
}</p>

<p>resampledCap &lt;&ndash; resampler(capreolusMatrix) #resample the original matrix-generate random coordinates
```
When the function finishes the output is also an XY matrix, which needs to be converted to an array in order to use it in gpagen function from the <em>geomorph</em> package. After that the procedure follows all the usual steps of the GM analysis, with the exception of factor levels generation in order to simulate grouping, and finally performing PCA on the Procrustes shape variables.</p>

<p><code>r Basic GM procedures and factor level generation
library(geomorph)
capreolusArray &lt;- arrayspecs(resampledCap, 28, 2, byLand = FALSE)
capreolusGPA &lt;- gpagen(capreolusArray, ShowPlot = FALSE)
pop &lt;- sample(5, 446, replace = TRUE) #generate random 5 population partition
pop[which(pop == 1)] &lt;- "pop1"
pop[which(pop == 2)] &lt;- "pop2"
pop[which(pop == 3)] &lt;- "pop3"
pop[which(pop == 4)] &lt;- "pop4"
pop[which(pop == 5)] &lt;- "pop5"
capreolusGPA2d &lt;- two.d.array(capreolusGPA$coords) #get the data in XY format for PCA
</code></p>

<p>PCA is then done using the usual R`s prcomp function and <em>ggplot2</em> for plotting the data points using fantastic <a href="http://colorbrewer2.org/" target="_blank">ColorBrewer</a> color schemes (which are the names of types and palettes in <em>ggplot2</em> scale_color_brewer geom). In order to fine-tune the PCA figure, the ggplot2 can also use custom fonts for plot annotation. Prior to that, fonts must be imported and registered, which is greatly facilitated by using the <em>extrafont</em> library.</p>

<p>```r PCA and ggplot2 code for a PCA scatterplot
capPCAwhole &lt;&ndash; prcomp(capreolusGPA2d)
capPCA &lt;&ndash; data.frame(capPCAwhole$x[,1], capPCAwhole$x[,2], capPCAwhole$x[,3], capPCAwhole$x[,4])
capPCA &lt;&ndash; data.frame(capPCA, pop)
names(capPCA) &lt;&ndash; c(&ldquo;PC1&rdquo;,&ldquo;PC2&rdquo;,&ldquo;PC3&rdquo;,&ldquo;PC4&rdquo;,&ldquo;pop&rdquo;) #prepare a data.frame for ggplot2
meanPCA1 &lt;&ndash; aggregate(capPCA[,1], mean, by = list(capPCA[,5])) #calculate average PC score per group for plotting
meanPCA2 &lt;&ndash; aggregate(capPCA[,2], mean, by = list(capPCA[,5]))
meanPCA &lt;&ndash; data.frame(meanPCA1, meanPCA2[,2])
names(meanPCA) &lt;&ndash; c(&ldquo;pop&rdquo;,&ldquo;PC1&rdquo;,&ldquo;PC2&rdquo;)</p>

<p>library(extrafont) #for using i.e. Times New Roman Fonts in ggplots
font_import(pattern=&ldquo;[T/t]imes&rdquo;) #this imports Times font family
loadfonts(device=&ldquo;pdf&rdquo;)</p>

<p>library (ggplot2)
theme_set(theme_bw())
pcaplot &lt;&ndash; ggplot(capPCA, aes(x=PC1, y=PC2, group = pop)) + geom_point(size = 7, shape = 19, aes(color=pop)) + scale_color_brewer(palette=&ldquo;Set1&rdquo;)
pcaplot &lt;&ndash; pcaplot + theme(panel.grid.major = element_line(size = 0.8, linetype = 2)) + theme(panel.grid.minor = element_line(size = 1, linetype = 2))
pcaplot &lt;&ndash; pcaplot + theme(text=element_text(size=20, family=&ldquo;Times New Roman&rdquo;), legend.text=element_text(size = 22, family = &ldquo;Times New Roman&rdquo;), legend.title = element_text(family =&ldquo;Times New Roman&rdquo;)) + xlab(&ldquo;PC1&rdquo;) + ylab(&ldquo;PC2&rdquo;)
pcaplot &lt;&ndash; pcaplot + geom_point(data = meanPCA, size = 14, shape = 19) + geom_text(data = meanPCA, size = 10, label = meanPCA$pop, family = &ldquo;Times New Roman&rdquo;, vjust = -0.9)
pcaplot
```</p>

<p><img class="center" src="/images/pcaplot.png" width="616" height="466" title="&lsquo;PCA&rsquo;" ></p>

<p>The plot indicates very little differentiation between the populations, but I guess that`s well expected since so much randomness is at hand.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Colorful Outlines for Shape Comparison]]></title>
    <link href="http://paulidealiste.github.io/blog/2014/01/09/colorful-outlines-for-shape-comparison/"/>
    <updated>2014-01-09T19:55:01+01:00</updated>
    <id>http://paulidealiste.github.io/blog/2014/01/09/colorful-outlines-for-shape-comparison</id>
    <content type="html"><![CDATA[<p>This procedure is based on the outlines generated from the digital photos using imageJ and converting imageJ images to x-y continuous outline data available from <a href="http://goo.gl/TYSzf0" target="_blank">here</a>. Its goal is to present a visual overview of global shape differences between roe deer (<em>Capreolus capreolus</em>) populations, using landmark data from ventral projection of their crania. All outlines are based on deformation via Thin Plate Splines, using mean shapes for populations as deformation targets and references. Superimposition methods as well as preliminary GM analyses were done in R and marvelous <em>geomorph</em> package by Dean Adams and Erik Otarola-Castillo. Additionally, since one of the common points of contemporary scientific research is the reproducibility of solutions offered all posts will also contain randomly generated sample data that could be used similarly to real-world datasets. Sample generation can be very useful, especially in teaching, so I intend to focus on it in future posts.</p>

<p><code>r Importing libraries and generating the basic dataset (files should be placed in your working directory)
library(geomorph)
library(ggplot2)
library(Morpho)
d &lt;- read.table("ventralnoOutlineCap.txt") #outline data
load("capreolusRgen.RData")
capreolusArray &lt;- capreolusSample1 #or capreolusSample2-5
</code>
The workspace &ldquo;capreolusRgen.RData&rdquo; (which can be downloaded from <a href="http://goo.gl/4uKerX" target="_blank">here</a>) contains several randomly generated datasetes of 657 individuals and 28 landmarks, named &ldquo;capreolusSample#&rdquo;. These data was generated on the basis of real-world values, using the linear regression model to control random number generators. The code that was used probably does not repoduce the sampling of landmarks well, especially regarding correlations between pairs of landmark coordinates or the landmarks that conform to the object symmetry, but for the purpose of illustration in this post, I hope they should be fine.</p>

<p><code>r Procrustes superimposition
capreolusGPA &lt;- gpagen(capreolusArray, ShowPlot = FALSE)
pop &lt;- sample(3, 657, replace = TRUE) #generate random 3 population partition
pop[which(pop == 1)] &lt;- "pop1"
pop[which(pop == 2)] &lt;- "pop2"
pop[which(pop == 3)] &lt;- "pop3"
capreolus &lt;- capreolusGPA$coords #extract landmark coordinates
</code></p>

<p>Following the Procrustes superimposition is the calculation of mean shapes, both for all males and for separate populations. After mean shapes are calculated the only thing left is to use TPS in order to deform outlines (variable d), using mean shape of all males as a reference and mean shape of populations as target. This can all be done using <em>Morpho</em> R-package from Stefan Schlager.</p>

<p><code>r Mean shapes and TPS deformations
meanCap &lt;- mshape(capreolus)
meanPop1 &lt;- mshape(capreolus[,,which(pop == "pop1")]) #by population
meanPop2 &lt;- mshape(capreolus[,,which(pop == "pop2")])
meanPop3 &lt;- mshape(capreolus[,,which(pop == "pop3")])
pop1 &lt;- data.frame(tps3d(as.matrix(d), meanCap, meanPop1)) #for each population
pop2 &lt;- data.frame(tps3d(as.matrix(d), meanCap, meanPop2))
pop3 &lt;- data.frame(tps3d(as.matrix(d), meanCap, meanPop3))
capWhole &lt;- rbind(pop1, pop2, pop3) #combine data
pops &lt;- c(rep("pop1", 2836), rep("pop2", 2836), rep("pop3", 2836)) #outline has 2836 points
</code></p>

<p>Finally, depicting shape changes can be achieved by wonderful Hadley Wickham`s <em>ggplot2</em> R-package. This package has a neat way of &ldquo;forcing&rdquo; you to keep your data organized, so all variables are inside one data frame, both quantitative and qualitative.</p>

<p><code>r ggplot2 plotting of shape outline deformations
wholeCap &lt;- data.frame(capWhole, pops) #deformed outlines and population membership
theme_set(theme_bw()) #change default ggplot theme to b&amp;w
dplot &lt;- ggplot(wholeCap, aes(wholeCap[,1],wholeCap[,2], group = pops)) #initialize ggplot object
dplot &lt;- dplot + geom_path(size = 1, aes(color = pops)) + facet_grid(.~pops) #add layers
dplot + theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())
</code></p>

<p><img class="center" src="/images/post1outline.png" width="616" height="546" title="&lsquo;Outlines&rsquo;" ></p>

<p>By inspecting outlines it can be seen that the individuals from pop1 are the smallest while the ones from pop2 are the largest. Shape differences are also determined by the relationship of length to width, so that individuals from pop2 have the widest crania, while the ones from pop1 have the narrowest. Also, it can be seen that in the individuals with the largest crania, size differences are detemined mostly by dimensions of the anterior part, maxillary and rostral regions, that are both wider and longer with respect to individuals with smaller crania. Posterior part of the cranium is more similar between individuals from different populations, and it may be more stable.</p>
]]></content>
  </entry>
  
</feed>
